{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5514c19c-de86-4ffa-a8e4-ddd790982d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'sentence', 'processed_text', 'sentiment_score',\n",
      "       'predicted_label'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>according gran company plan move production ru...</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>technopolis plan develop stage area less 100 0...</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>international electronic industry company elco...</td>\n",
       "      <td>-0.053333</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>new production plant company would increase ca...</td>\n",
       "      <td>0.595251</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>according company updated strategy year 2009 2...</td>\n",
       "      <td>0.539287</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           sentence  \\\n",
       "0   neutral  According to Gran , the company has no plans t...   \n",
       "1   neutral  Technopolis plans to develop in stages an area...   \n",
       "2  negative  The international electronic industry company ...   \n",
       "3  positive  With the new production plant the company woul...   \n",
       "4  positive  According to the company 's updated strategy f...   \n",
       "\n",
       "                                      processed_text  sentiment_score  \\\n",
       "0  according gran company plan move production ru...         0.059300   \n",
       "1  technopolis plan develop stage area less 100 0...        -0.055556   \n",
       "2  international electronic industry company elco...        -0.053333   \n",
       "3  new production plant company would increase ca...         0.595251   \n",
       "4  according company updated strategy year 2009 2...         0.539287   \n",
       "\n",
       "  predicted_label  \n",
       "0        positive  \n",
       "1        negative  \n",
       "2        negative  \n",
       "3        positive  \n",
       "4        positive  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load processed dataset\n",
    "data = pd.read_csv(\"processed_financial_data.xls\")\n",
    "\n",
    "# Check columns\n",
    "print(data.columns)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b89b6b-beab-4555-bd1c-1a7df12f0623",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"negative\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"positive\": 2\n",
    "}\n",
    "\n",
    "data[\"label_id\"] = data[\"label\"].map(label_map)\n",
    "data = data.dropna(subset=[\"label_id\"])\n",
    "\n",
    "# Convert to int\n",
    "data[\"label_id\"] = data[\"label_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb6b6e3-d778-4aaa-92eb-adfeb0083f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4119\n",
      "Validation size: 727\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data[\"sentence\"].astype(str).tolist(),\n",
    "    data[\"label_id\"].tolist(),\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=data[\"label_id\"]\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_texts))\n",
    "print(\"Validation size:\", len(val_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a16993-53d8-4e30-b4a7-303da07a00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class FinBERTFineTuner:\n",
    "    def __init__(self, model_name=\"ProsusAI/finbert\"):\n",
    "        \"\"\"Initialize for fine-tuning.\"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    def prepare_dataset(self, texts, labels, max_length=128):\n",
    "        \"\"\"\n",
    "        Prepare texts for training.\n",
    "        FinBERT expects: [text, label]\n",
    "        \"\"\"\n",
    "        def tokenize_function(examples):\n",
    "            return self.tokenizer(\n",
    "                examples['text'],\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=max_length\n",
    "            )\n",
    "        \n",
    "        dataset = Dataset.from_dict({\n",
    "            'text': texts,\n",
    "            'label': labels\n",
    "        })\n",
    "        \n",
    "        tokenized_dataset = dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=['text']\n",
    "        )\n",
    "        \n",
    "        return tokenized_dataset\n",
    "    \n",
    "    def fine_tune(self, train_texts, train_labels, val_texts, val_labels, \n",
    "                  num_epochs=3, batch_size=16, learning_rate=2e-5):\n",
    "        \"\"\"\n",
    "        Fine-tune FinBERT on your data.\n",
    "        \n",
    "        Parameters:\n",
    "        - num_epochs: 3 is typical (more overfits, less undertains)\n",
    "        - batch_size: 16 for Colab GPU, 8 if memory limited\n",
    "        - learning_rate: 2e-5 is standard for fine-tuning\n",
    "        \"\"\"\n",
    "        \n",
    "        # Prepare datasets\n",
    "        train_dataset = self.prepare_dataset(train_texts, train_labels)\n",
    "        val_dataset = self.prepare_dataset(val_texts, val_labels)\n",
    "        \n",
    "        # Define training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./finbert_finetuned',\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_steps=100,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            greater_is_better=True,\n",
    "            save_total_limit=2,\n",
    "        )\n",
    "        \n",
    "        # Define metrics\n",
    "        def compute_metrics(eval_preds):\n",
    "            predictions, labels = eval_preds\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            accuracy = (predictions == labels).mean()\n",
    "            precision = precision_score(labels, predictions, average='weighted', zero_division=0)\n",
    "            recall = recall_score(labels, predictions, average='weighted', zero_division=0)\n",
    "            f1 = f1_score(labels, predictions, average='weighted', zero_division=0)\n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1\n",
    "            }\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        print(\"Starting fine-tuning...\")\n",
    "        trainer.train()\n",
    "        print(\"Fine-tuning complete!\")\n",
    "        \n",
    "        return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de00d052-fdda-4152-aeed-4a0290f9f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026f115c-ca8a-4194-a3db-a4006101f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (4.4.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from accelerate) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from accelerate) (2.9.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.6.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user hp\\financial-news-sentiment-analysis\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U accelerate datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea013e22-dc38-4c4e-8049-65fc92117b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb986bc-2a0f-4cd8-803d-9c2d1f63f2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aead61c064b34d7486667cbae92f6730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891ca3760acd4d37aa7aa50a8c1f2b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER HP\\Financial-News-Sentiment-Analysis\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1030' max='1030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1030/1030 4:37:30, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.508773</td>\n",
       "      <td>0.855571</td>\n",
       "      <td>0.859625</td>\n",
       "      <td>0.855571</td>\n",
       "      <td>0.856323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "# Initialize fine-tuner\n",
    "finbert_trainer = FinBERTFineTuner()\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer = finbert_trainer.fine_tune(\n",
    "    train_texts=train_texts,\n",
    "    train_labels=train_labels,\n",
    "    val_texts=val_texts,\n",
    "    val_labels=val_labels,\n",
    "    num_epochs=1,      \n",
    "    batch_size=4,         \n",
    "    learning_rate=2e-5     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e400ee9-ed8b-4890-9137-c0da44f496ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
